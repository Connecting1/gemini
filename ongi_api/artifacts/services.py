# artifacts/services.py

import httpx
import json
from typing import Generator, Dict, Any
from django.conf import settings

class OllamaService:
    """Ollama AI ì„œë¹„ìŠ¤"""
    
    OLLAMA_BASE_URL = getattr(settings, 'OLLAMA_BASE_URL', 'http://localhost:11434')
    DEFAULT_MODEL = getattr(settings, 'OLLAMA_MODEL', 'llama3.1:8b')
    
    @classmethod
    def generate_artifact_description(
        cls, 
        artifact_name: str,
        time_period: str = None,
        estimated_year: str = None,
        origin_location: str = None,
        stream: bool = True
    ) -> Generator[Dict[str, Any], None, None]:
        """
        ìœ ë¬¼ ì„¤ëª… ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
        
        Args:
            artifact_name: ìœ ë¬¼ëª…
            time_period: ì‹œëŒ€
            estimated_year: ì¶”ì • ì—°ë„
            origin_location: ì¶œí† ì§€
            stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€
        
        Yields:
            {'chunk': 'í…ìŠ¤íŠ¸'} ë˜ëŠ” {'done': True} ë˜ëŠ” {'error': 'ì—ëŸ¬ë©”ì‹œì§€'}
        """
        
        # âœ¨ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = cls._create_prompt(
            artifact_name=artifact_name,
            time_period=time_period,
            estimated_year=estimated_year,
            origin_location=origin_location,
        )
        
        try:
            with httpx.stream(
                'POST',
                f'{cls.OLLAMA_BASE_URL}/api/generate',
                json={
                    'model': cls.DEFAULT_MODEL,
                    'prompt': prompt,
                    'stream': stream,
                    'options': {
                        'temperature': 0.7,  # ì°½ì˜ì„± ì¡°ì ˆ
                        'top_p': 0.9,
                        'max_tokens': 500,   # ìµœëŒ€ í† í° ìˆ˜
                    }
                },
                timeout=60.0
            ) as response:
                
                if response.status_code != 200:
                    yield {'error': f'Ollama API error: {response.status_code}'}
                    return
                
                for line in response.iter_lines():
                    if line.strip():
                        try:
                            data = json.loads(line)
                            
                            if 'response' in data:
                                yield {'chunk': data['response']}
                            
                            if data.get('done', False):
                                yield {'done': True}
                                break
                                
                        except json.JSONDecodeError as e:
                            yield {'error': f'JSON decode error: {str(e)}'}
                            continue
                            
        except httpx.TimeoutException:
            yield {'error': 'Ollama API timeout'}
        except httpx.ConnectError:
            yield {'error': 'Cannot connect to Ollama. Is it running?'}
        except Exception as e:
            yield {'error': f'Unexpected error: {str(e)}'}
    
    @classmethod
    def _create_prompt(
        cls,
        artifact_name: str,
        time_period: str = None,
        estimated_year: str = None,
        origin_location: str = None,
    ) -> str:
        """ìœ ë¬¼ ì„¤ëª… ìƒì„± í”„ë¡¬í”„íŠ¸"""
        
        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ë¬¸í™”ì¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìœ ë¬¼ì— ëŒ€í•´ ìì„¸í•˜ê³  í¥ë¯¸ë¡­ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ“Œ ìœ ë¬¼ ì •ë³´:
- ìœ ë¬¼ëª…: {artifact_name}"""
        
        if time_period:
            prompt += f"\nâ€¢ ì‹œëŒ€: {time_period}"
        if estimated_year:
            prompt += f"\nâ€¢ ì¶”ì • ì—°ë„: {estimated_year}"
        if origin_location:
            prompt += f"\nâ€¢ ì¶œí† ì§€: {origin_location}"
        
        prompt += """

ğŸ“ ì„¤ëª… ì‘ì„± ê°€ì´ë“œ:
1. ì—­ì‚¬ì  ë°°ê²½ê³¼ ì‹œëŒ€ì  ë§¥ë½ (2-3ë¬¸ì¥)
2. ìœ ë¬¼ì˜ íŠ¹ì§•ê³¼ ì œì‘ ê¸°ë²• (2-3ë¬¸ì¥)
3. ë¬¸í™”ì /ì˜ˆìˆ ì  ê°€ì¹˜ì™€ ì˜ì˜ (1-2ë¬¸ì¥)

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- í¥ë¯¸ë¡œìš´ ì´ì•¼ê¸°ë‚˜ ì—í”¼ì†Œë“œ í¬í•¨
- ì´ 200-300ì ë‚´ì™¸ë¡œ ì‘ì„±
- ì¡´ëŒ“ë§ ì‚¬ìš©í•˜ì§€ ì•Šê³  í‰ì„œë¬¸ìœ¼ë¡œ ì‘ì„±

ì„¤ëª…:"""
        
        return prompt
    
    @classmethod
    def generate_simple(cls, artifact_name: str) -> str:
        """
        ê°„ë‹¨í•œ ë™ê¸°ì‹ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ì—†ìŒ)
        """
        full_text = ""
        
        for chunk in cls.generate_artifact_description(
            artifact_name=artifact_name,
            stream=True
        ):
            if 'chunk' in chunk:
                full_text += chunk['chunk']
            elif 'error' in chunk:
                raise Exception(chunk['error'])
            elif chunk.get('done'):
                break
        
        return full_text